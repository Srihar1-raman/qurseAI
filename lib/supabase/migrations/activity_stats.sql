-- =====================================================
-- GLOBAL ACTIVITY STATS - MATERIALIZED VIEW
-- =====================================================

-- Create table for pre-aggregated daily activity stats
CREATE TABLE IF NOT EXISTS daily_activity_stats (
  id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
  activity_date DATE NOT NULL UNIQUE,
  messages_count INTEGER DEFAULT 0,
  conversations_count INTEGER DEFAULT 0,
  input_tokens BIGINT DEFAULT 0,
  output_tokens BIGINT DEFAULT 0,
  total_tokens BIGINT DEFAULT 0,
  metrics JSONB DEFAULT '{}'::jsonb,
  updated_at TIMESTAMPTZ DEFAULT NOW() NOT NULL
);

-- Index for performance
CREATE INDEX IF NOT EXISTS idx_daily_activity_stats_date
ON daily_activity_stats(activity_date DESC);

-- GIN index for JSONB metrics
CREATE INDEX IF NOT EXISTS idx_daily_activity_stats_metrics
ON daily_activity_stats USING GIN (metrics);

-- =====================================================
-- INCREMENTAL UPDATE FUNCTION
-- Called every 6 hours via cron
-- =====================================================

CREATE OR REPLACE FUNCTION update_daily_activity_stats()
RETURNS void AS $$
DECLARE
  today_exists BOOLEAN;
BEGIN
  -- Check if today's stats already exist
  SELECT EXISTS (
    SELECT 1 FROM daily_activity_stats
    WHERE activity_date = CURRENT_DATE
  ) INTO today_exists;

  IF today_exists THEN
    -- Update today's stats (incremental)
    UPDATE daily_activity_stats
    SET
      messages_count = subq.messages,
      conversations_count = subq.conversations,
      input_tokens = subq.input_tokens,
      output_tokens = subq.output_tokens,
      total_tokens = subq.total_tokens,
      metrics = subq.metrics,
      updated_at = NOW()
    FROM (
      SELECT
        COUNT(DISTINCT m.id)::INTEGER as messages,
        COUNT(DISTINCT m.conversation_id)::INTEGER as conversations,
        COALESCE(SUM(m.input_tokens), 0)::BIGINT as input_tokens,
        COALESCE(SUM(m.output_tokens), 0)::BIGINT as output_tokens,
        COALESCE(SUM(m.total_tokens), 0)::BIGINT as total_tokens,
        -- Aggregate model-specific metrics into JSONB
        COALESCE(
          (
            SELECT JSONB_BUILD_OBJECT(
              'models', JSONB_OBJECT_AGG(
                model,
                JSONB_BUILD_OBJECT(
                  'messages', msg_count,
                  'inputTokens', COALESCE(input_tokens, 0),
                  'outputTokens', COALESCE(output_tokens, 0),
                  'totalTokens', COALESCE(total_tokens, 0),
                  'conversations', conversation_count
                )
              )
            )
            FROM (
              SELECT
                -- Clean model name to match frontend transformer (remove provider prefixes)
                REGEXP_REPLACE(model, '^(openai|anthropic)/', '') as model,
                COUNT(DISTINCT id) as msg_count,
                SUM(input_tokens) as input_tokens,
                SUM(output_tokens) as output_tokens,
                SUM(total_tokens) as total_tokens,
                COUNT(DISTINCT conversation_id) as conversation_count
              FROM messages
              WHERE DATE(created_at) = CURRENT_DATE
                AND role = 'assistant'
                AND model IS NOT NULL
              GROUP BY REGEXP_REPLACE(model, '^(openai|anthropic)/', '')
            ) model_data
          ),
          '{}'::jsonb
        ) as metrics
      FROM messages m
      WHERE DATE(m.created_at) = CURRENT_DATE
        AND m.role = 'assistant'
    ) subq
    WHERE daily_activity_stats.activity_date = CURRENT_DATE;

  ELSE
    -- Insert new stats for today
    INSERT INTO daily_activity_stats (
      activity_date,
      messages_count,
      conversations_count,
      input_tokens,
      output_tokens,
      total_tokens,
      metrics
    )
    SELECT
      CURRENT_DATE,
      COUNT(DISTINCT m.id)::INTEGER,
      COUNT(DISTINCT m.conversation_id)::INTEGER,
      COALESCE(SUM(m.input_tokens), 0)::BIGINT,
      COALESCE(SUM(m.output_tokens), 0)::BIGINT,
      COALESCE(SUM(m.total_tokens), 0)::BIGINT,
      -- Same model aggregation as above
      COALESCE(
        (
          SELECT JSONB_BUILD_OBJECT(
            'models', JSONB_OBJECT_AGG(
              model,
              JSONB_BUILD_OBJECT(
                'messages', msg_count,
                'inputTokens', COALESCE(input_tokens, 0),
                'outputTokens', COALESCE(output_tokens, 0),
                'totalTokens', COALESCE(total_tokens, 0),
                'conversations', conversation_count
              )
            )
          )
          FROM (
            SELECT
              -- Clean model name to match frontend transformer (remove provider prefixes)
              REGEXP_REPLACE(model, '^(openai|anthropic)/', '') as model,
              COUNT(DISTINCT id) as msg_count,
              SUM(input_tokens) as input_tokens,
              SUM(output_tokens) as output_tokens,
              SUM(total_tokens) as total_tokens,
              COUNT(DISTINCT conversation_id) as conversation_count
            FROM messages
            WHERE DATE(created_at) = CURRENT_DATE
              AND role = 'assistant'
              AND model IS NOT NULL
            GROUP BY REGEXP_REPLACE(model, '^(openai|anthropic)/', '')
          ) model_data
        ),
        '{}'::jsonb
      )
    FROM messages m
    WHERE DATE(m.created_at) = CURRENT_DATE
      AND m.role = 'assistant';

  END IF;
END;
$$ LANGUAGE plpgsql;

-- Grant execute permission (for cron jobs)
GRANT EXECUTE ON FUNCTION update_daily_activity_stats() TO authenticated;
GRANT EXECUTE ON FUNCTION update_daily_activity_stats() TO anon;

-- =====================================================
-- CRON JOB SETUP (pg_cron)
-- =====================================================

-- Check if pg_cron is available
SELECT
  CASE
    WHEN EXISTS (
      SELECT 1 FROM pg_extension WHERE extname = 'pg_cron'
    )
    THEN 'pg_cron is installed âœ“'
    ELSE 'pg_cron not installed - use Supabase Dashboard cron instead'
  END as pg_cron_status;

-- Schedule cron job (uncomment if pg_cron is available)
-- This will run every 6 hours at 00:00, 06:00, 12:00, 18:00 UTC
SELECT cron.schedule(
  'update-activity-stats',
  '0 */6 * * *',
  'SELECT update_daily_activity_stats()'
);

-- Verify cron job was scheduled
SELECT
  jobid,
  schedule,
  command,
  database,
  active
FROM cron.job
WHERE jobid IN (
  SELECT jobid FROM cron.job WHERE command LIKE '%update_daily_activity_stats%'
);

-- =====================================================
-- MANUAL TEST (optional)
-- =====================================================

-- Test the update function manually:
-- SELECT update_daily_activity_stats();

-- =====================================================
-- SETUP COMPLETE
-- =====================================================

SELECT 'Global activity stats setup complete! ðŸŽ‰' as status;
